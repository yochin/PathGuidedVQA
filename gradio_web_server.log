2024-02-02 10:07:39 | INFO | gradio_web_server | args: Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:10000', concurrency_count=8, model_list_mode='reload', share=False, moderate=False, embed=False, add_region_feature=False)
2024-02-02 10:07:39 | INFO | gradio_web_server | Models: []
2024-02-02 10:07:39 | INFO | gradio_web_server | Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:10000', concurrency_count=8, model_list_mode='reload', share=False, moderate=False, embed=False, add_region_feature=False)
2024-02-02 10:07:39 | ERROR | stderr | /home/yochin/miniconda3/envs/ferret/lib/python3.10/site-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Textbox, please remove them: {'container': False}
2024-02-02 10:07:39 | ERROR | stderr |   warnings.warn(
2024-02-02 10:07:40 | ERROR | stderr | /home/yochin/miniconda3/envs/ferret/lib/python3.10/site-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Dropdown, please remove them: {'container': False}
2024-02-02 10:07:40 | ERROR | stderr |   warnings.warn(
2024-02-02 10:07:40 | INFO | stdout | Running on local URL:  http://0.0.0.0:7860
2024-02-02 10:07:40 | INFO | stdout | 
2024-02-02 10:07:40 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-02-02 10:10:58 | INFO | gradio_web_server | load_demo. ip: 127.0.0.1
2024-02-02 10:10:58 | INFO | gradio_web_server | Models: ['ferret-13b-v1.3']
2024-02-02 10:11:04 | INFO | stdout | Init Uploading Images.
2024-02-02 10:11:28 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 70
2024-02-02 10:11:28 | INFO | stdout | No location, copy original image in add_text
2024-02-02 10:11:28 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 10:11:28 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 10:11:28 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:11:28 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:11:28 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': "A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nWhat's the relationship between object [region0] and object [region1]? ASSISTANT:", 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['46c4c809a7f524e0d1c3eee44d673eee']"}
2024-02-02 10:11:28 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:11:28 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 10:11:28 | INFO | stdout | What's the relationship between object [region0] and object [region1]? ASSISTANT:
2024-02-02 10:11:47 | INFO | gradio_web_server | Subject: tree trunk [87, 0, 146, 356]. Predicate: in. Object: background [10, 6, 990, 343].
2024-02-02 10:11:47 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:12:30 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-02-02 10:13:43 | INFO | gradio_web_server | args: Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:10000', concurrency_count=8, model_list_mode='reload', share=False, moderate=False, embed=False, add_region_feature=False)
2024-02-02 10:13:43 | INFO | gradio_web_server | Models: []
2024-02-02 10:13:43 | INFO | gradio_web_server | Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:10000', concurrency_count=8, model_list_mode='reload', share=False, moderate=False, embed=False, add_region_feature=False)
2024-02-02 10:13:43 | ERROR | stderr | /home/yochin/miniconda3/envs/ferret/lib/python3.10/site-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Textbox, please remove them: {'container': False}
2024-02-02 10:13:43 | ERROR | stderr |   warnings.warn(
2024-02-02 10:13:43 | ERROR | stderr | /home/yochin/miniconda3/envs/ferret/lib/python3.10/site-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Dropdown, please remove them: {'container': False}
2024-02-02 10:13:43 | ERROR | stderr |   warnings.warn(
2024-02-02 10:13:43 | INFO | stdout | Running on local URL:  http://0.0.0.0:7860
2024-02-02 10:13:43 | INFO | stdout | 
2024-02-02 10:13:43 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-02-02 10:14:53 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-02-02 10:15:21 | INFO | gradio_web_server | args: Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:10000', concurrency_count=8, model_list_mode='reload', share=False, moderate=False, embed=False, add_region_feature=True)
2024-02-02 10:15:21 | INFO | gradio_web_server | Models: []
2024-02-02 10:15:21 | INFO | gradio_web_server | Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:10000', concurrency_count=8, model_list_mode='reload', share=False, moderate=False, embed=False, add_region_feature=True)
2024-02-02 10:15:21 | ERROR | stderr | /home/yochin/miniconda3/envs/ferret/lib/python3.10/site-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Textbox, please remove them: {'container': False}
2024-02-02 10:15:21 | ERROR | stderr |   warnings.warn(
2024-02-02 10:15:22 | ERROR | stderr | /home/yochin/miniconda3/envs/ferret/lib/python3.10/site-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Dropdown, please remove them: {'container': False}
2024-02-02 10:15:22 | ERROR | stderr |   warnings.warn(
2024-02-02 10:15:22 | INFO | stdout | Running on local URL:  http://0.0.0.0:7860
2024-02-02 10:15:22 | INFO | stdout | 
2024-02-02 10:15:22 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-02-02 10:16:19 | INFO | gradio_web_server | load_demo. ip: 127.0.0.1
2024-02-02 10:16:19 | INFO | gradio_web_server | Models: ['ferret-13b-v1.3']
2024-02-02 10:16:38 | INFO | stdout | Init Uploading Images.
2024-02-02 10:16:59 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 30
2024-02-02 10:16:59 | INFO | stdout | No location, copy original image in add_text
2024-02-02 10:17:00 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 10:17:00 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 10:17:00 | INFO | stdout | Input Image Size:(1066, 800)
2024-02-02 10:17:00 | INFO | stdout | Input Image Size:(1066, 800)
2024-02-02 10:17:00 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': 'A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nDescribe the object [468, 553] <region_fea>. ASSISTANT:', 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['7dd240737aaa8942e1f51625050962b0']"}
2024-02-02 10:17:00 | INFO | gradio_web_server | ==== add region_masks_in_prompts to request ====

2024-02-02 10:17:00 | INFO | stdout | Input Image Size:(1066, 800)
2024-02-02 10:17:00 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 10:17:00 | INFO | stdout | Describe the object [468, 553] <region_fea>. ASSISTANT:
2024-02-02 10:17:56 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-02-02 10:30:55 | INFO | gradio_web_server | args: Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:10000', concurrency_count=8, model_list_mode='reload', share=False, moderate=False, embed=False, add_region_feature=True)
2024-02-02 10:30:55 | INFO | gradio_web_server | Models: ['ferret-13b-v1.3']
2024-02-02 10:30:55 | INFO | gradio_web_server | Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:10000', concurrency_count=8, model_list_mode='reload', share=False, moderate=False, embed=False, add_region_feature=True)
2024-02-02 10:30:55 | ERROR | stderr | /home/yochin/miniconda3/envs/ferret/lib/python3.10/site-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Textbox, please remove them: {'container': False}
2024-02-02 10:30:55 | ERROR | stderr |   warnings.warn(
2024-02-02 10:30:56 | ERROR | stderr | /home/yochin/miniconda3/envs/ferret/lib/python3.10/site-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Dropdown, please remove them: {'container': False}
2024-02-02 10:30:56 | ERROR | stderr |   warnings.warn(
2024-02-02 10:30:56 | INFO | stdout | Running on local URL:  http://0.0.0.0:7860
2024-02-02 10:30:56 | INFO | stdout | 
2024-02-02 10:30:56 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-02-02 10:31:01 | ERROR | stderr | [33mWARNING[0m:  Invalid HTTP request received.
2024-02-02 10:31:02 | ERROR | stderr | [33mWARNING[0m:  Invalid HTTP request received.
2024-02-02 10:31:02 | ERROR | stderr | [33mWARNING[0m:  Invalid HTTP request received.
2024-02-02 10:31:04 | INFO | gradio_web_server | load_demo. ip: 127.0.0.1
2024-02-02 10:31:04 | INFO | gradio_web_server | Models: ['ferret-13b-v1.3']
2024-02-02 10:31:12 | INFO | stdout | Init Uploading Images.
2024-02-02 10:31:28 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 30
2024-02-02 10:31:28 | INFO | stdout | No location, copy original image in add_text
2024-02-02 10:31:29 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 10:31:29 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 10:31:29 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 10:31:29 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 10:31:29 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': 'A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nDescribe the object [317, 536] <region_fea>. ASSISTANT:', 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['e46a4f1784c124ae3b7bc2602a128e8b']"}
2024-02-02 10:31:29 | INFO | gradio_web_server | ==== add region_masks_in_prompts to request ====

2024-02-02 10:31:29 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 10:31:29 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 10:31:29 | INFO | stdout | Describe the object [317, 536] <region_fea>. ASSISTANT:
2024-02-02 10:33:38 | INFO | gradio_web_server | load_demo. ip: 127.0.0.1
2024-02-02 10:33:38 | INFO | gradio_web_server | Models: []
2024-02-02 10:33:40 | INFO | gradio_web_server | load_demo. ip: 127.0.0.1
2024-02-02 10:33:40 | INFO | gradio_web_server | Models: ['ferret-13b-v1.3']
2024-02-02 10:33:41 | INFO | gradio_web_server | load_demo. ip: 127.0.0.1
2024-02-02 10:33:41 | INFO | gradio_web_server | Models: ['ferret-13b-v1.3']
2024-02-02 10:33:47 | INFO | stdout | Init Uploading Images.
2024-02-02 10:34:10 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 30
2024-02-02 10:34:10 | INFO | stdout | No location, copy original image in add_text
2024-02-02 10:34:10 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 10:34:10 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 10:34:10 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 10:34:10 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 10:34:10 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': 'A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nDescribe the region [0, 518, 480, 998] <region_fea>. ASSISTANT:', 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['e46a4f1784c124ae3b7bc2602a128e8b']"}
2024-02-02 10:34:10 | INFO | gradio_web_server | ==== add region_masks_in_prompts to request ====

2024-02-02 10:34:10 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 10:34:11 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 10:34:11 | INFO | stdout | Describe the region [0, 518, 480, 998] <region_fea>. ASSISTANT:
2024-02-02 10:35:50 | ERROR | stderr | Traceback (most recent call last):
2024-02-02 10:35:50 | ERROR | stderr |   File "/home/yochin/miniconda3/envs/ferret/lib/python3.10/site-packages/gradio/routes.py", line 401, in run_predict
2024-02-02 10:35:50 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-02-02 10:35:50 | ERROR | stderr |   File "/home/yochin/miniconda3/envs/ferret/lib/python3.10/site-packages/gradio/blocks.py", line 1302, in process_api
2024-02-02 10:35:50 | ERROR | stderr |     result = await self.call_function(
2024-02-02 10:35:50 | ERROR | stderr |   File "/home/yochin/miniconda3/envs/ferret/lib/python3.10/site-packages/gradio/blocks.py", line 1025, in call_function
2024-02-02 10:35:50 | ERROR | stderr |     prediction = await anyio.to_thread.run_sync(
2024-02-02 10:35:50 | ERROR | stderr |   File "/home/yochin/miniconda3/envs/ferret/lib/python3.10/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-02-02 10:35:50 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-02-02 10:35:50 | ERROR | stderr |   File "/home/yochin/miniconda3/envs/ferret/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 2134, in run_sync_in_worker_thread
2024-02-02 10:35:50 | ERROR | stderr |     return await future
2024-02-02 10:35:50 | ERROR | stderr |   File "/home/yochin/miniconda3/envs/ferret/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-02-02 10:35:50 | ERROR | stderr |     result = context.run(func, *args)
2024-02-02 10:35:50 | ERROR | stderr |   File "/home/yochin/Desktop/PathGuidedVQA_Base/PathGuidedVQA/ferret/serve/gradio_web_server.py", line 556, in draw
2024-02-02 10:35:50 | ERROR | stderr |     diff_mask = mask_new - last_mask
2024-02-02 10:35:50 | ERROR | stderr | RuntimeError: The size of tensor a (465) must match the size of tensor b (800) at non-singleton dimension 1
2024-02-02 10:37:11 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-02-02 10:37:20 | INFO | gradio_web_server | args: Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:10000', concurrency_count=8, model_list_mode='reload', share=False, moderate=False, embed=False, add_region_feature=True)
2024-02-02 10:37:20 | INFO | gradio_web_server | Models: ['ferret-13b-v1.3']
2024-02-02 10:37:20 | INFO | gradio_web_server | Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:10000', concurrency_count=8, model_list_mode='reload', share=False, moderate=False, embed=False, add_region_feature=True)
2024-02-02 10:37:20 | ERROR | stderr | /home/yochin/miniconda3/envs/ferret/lib/python3.10/site-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Textbox, please remove them: {'container': False}
2024-02-02 10:37:20 | ERROR | stderr |   warnings.warn(
2024-02-02 10:37:21 | ERROR | stderr | /home/yochin/miniconda3/envs/ferret/lib/python3.10/site-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Dropdown, please remove them: {'container': False}
2024-02-02 10:37:21 | ERROR | stderr |   warnings.warn(
2024-02-02 10:37:21 | INFO | stdout | Running on local URL:  http://0.0.0.0:7860
2024-02-02 10:37:21 | INFO | stdout | 
2024-02-02 10:37:21 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-02-02 10:37:33 | INFO | gradio_web_server | load_demo. ip: 127.0.0.1
2024-02-02 10:37:33 | INFO | gradio_web_server | Models: ['ferret-13b-v1.3']
2024-02-02 10:37:35 | INFO | stdout | Init Uploading Images.
2024-02-02 10:37:54 | INFO | gradio_web_server | load_demo. ip: 127.0.0.1
2024-02-02 10:37:54 | INFO | gradio_web_server | Models: ['ferret-13b-v1.3']
2024-02-02 10:37:57 | INFO | stdout | Init Uploading Images.
2024-02-02 10:38:08 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 70
2024-02-02 10:38:08 | INFO | stdout | No location, copy original image in add_text
2024-02-02 10:38:08 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 10:38:08 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 10:38:08 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:38:08 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:38:08 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': "A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nWhat's the relationship between object [229, 619] <region_fea> and object [354, 187, 899, 763] <region_fea>? ASSISTANT:", 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['46c4c809a7f524e0d1c3eee44d673eee']"}
2024-02-02 10:38:08 | INFO | gradio_web_server | ==== add region_masks_in_prompts to request ====

2024-02-02 10:38:08 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:38:08 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 10:38:08 | INFO | stdout | What's the relationship between object [229, 619] <region_fea> and object [354, 187, 899, 763] <region_fea>? ASSISTANT:
2024-02-02 10:40:40 | INFO | gradio_web_server | regenerate. ip: 127.0.0.1
2024-02-02 10:40:40 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 10:40:40 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 10:40:40 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:40:40 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:40:40 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': "A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nWhat's the relationship between object [229, 619] <region_fea> and object [354, 187, 899, 763] <region_fea>? ASSISTANT:", 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['46c4c809a7f524e0d1c3eee44d673eee']"}
2024-02-02 10:40:40 | INFO | gradio_web_server | ==== add region_masks_in_prompts to request ====

2024-02-02 10:40:40 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:40:41 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 10:40:41 | INFO | stdout | What's the relationship between object [229, 619] <region_fea> and object [354, 187, 899, 763] <region_fea>? ASSISTANT:
2024-02-02 10:40:44 | INFO | gradio_web_server | regenerate. ip: 127.0.0.1
2024-02-02 10:40:44 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 10:40:44 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 10:40:44 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:40:44 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:40:45 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': "A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nWhat's the relationship between object [229, 619] <region_fea> and object [354, 187, 899, 763] <region_fea>? ASSISTANT:", 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['46c4c809a7f524e0d1c3eee44d673eee']"}
2024-02-02 10:40:45 | INFO | gradio_web_server | ==== add region_masks_in_prompts to request ====

2024-02-02 10:40:45 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:40:45 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 10:40:45 | INFO | stdout | What's the relationship between object [229, 619] <region_fea> and object [354, 187, 899, 763] <region_fea>? ASSISTANT:
2024-02-02 10:40:46 | INFO | gradio_web_server | regenerate. ip: 127.0.0.1
2024-02-02 10:40:46 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 10:40:46 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 10:40:46 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:40:46 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:40:46 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': "A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nWhat's the relationship between object [229, 619] <region_fea> and object [354, 187, 899, 763] <region_fea>? ASSISTANT:", 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['46c4c809a7f524e0d1c3eee44d673eee']"}
2024-02-02 10:40:46 | INFO | gradio_web_server | ==== add region_masks_in_prompts to request ====

2024-02-02 10:40:46 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:40:46 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 10:40:46 | INFO | stdout | What's the relationship between object [229, 619] <region_fea> and object [354, 187, 899, 763] <region_fea>? ASSISTANT:
2024-02-02 10:40:48 | INFO | gradio_web_server | regenerate. ip: 127.0.0.1
2024-02-02 10:40:48 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 10:40:48 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 10:40:48 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:40:48 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:40:48 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': "A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nWhat's the relationship between object [229, 619] <region_fea> and object [354, 187, 899, 763] <region_fea>? ASSISTANT:", 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['46c4c809a7f524e0d1c3eee44d673eee']"}
2024-02-02 10:40:48 | INFO | gradio_web_server | ==== add region_masks_in_prompts to request ====

2024-02-02 10:40:48 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:40:48 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 10:40:48 | INFO | stdout | What's the relationship between object [229, 619] <region_fea> and object [354, 187, 899, 763] <region_fea>? ASSISTANT:
2024-02-02 10:41:47 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 88
2024-02-02 10:41:47 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 10:41:47 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 10:41:47 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:41:47 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:41:47 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': "A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nWhat's the relationship between object [229, 619] <region_fea> and object [354, 187, 899, 763] <region_fea>? ASSISTANT: **NETWORK ERROR DUE TO HIGH TRAFFIC. PLEASE REGENERATE OR REFRESH THIS PAGE.** (error_code: 1)</s>USER: What’s the relationship between object [229, 619] <region_fea>, object [354, 187, 899, 763] <region_fea> and object [region3]? ASSISTANT:", 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['46c4c809a7f524e0d1c3eee44d673eee']"}
2024-02-02 10:41:47 | INFO | gradio_web_server | ==== add region_masks_in_prompts to request ====

2024-02-02 10:41:47 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:41:48 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 10:41:48 | INFO | stdout | What's the relationship between object [229, 619] <region_fea> and object [354, 187, 899, 763] <region_fea>? ASSISTANT: **NETWORK ERROR DUE TO HIGH TRAFFIC. PLEASE REGENERATE OR REFRESH THIS PAGE.** (error_code: 1)</s>USER: What’s the relationship between object [229, 619] <region_fea>, object [354, 187, 899, 763] <region_fea> and object [region3]? ASSISTANT:
2024-02-02 10:42:17 | INFO | gradio_web_server | regenerate. ip: 127.0.0.1
2024-02-02 10:42:17 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 10:42:17 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 10:42:17 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:42:17 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:42:17 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': "A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nWhat's the relationship between object [229, 619] <region_fea> and object [354, 187, 899, 763] <region_fea>? ASSISTANT: **NETWORK ERROR DUE TO HIGH TRAFFIC. PLEASE REGENERATE OR REFRESH THIS PAGE.** (error_code: 1)</s>USER: What’s the relationship between object [229, 619] <region_fea>, object [354, 187, 899, 763] <region_fea> and object [region3]? ASSISTANT:", 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['46c4c809a7f524e0d1c3eee44d673eee']"}
2024-02-02 10:42:17 | INFO | gradio_web_server | ==== add region_masks_in_prompts to request ====

2024-02-02 10:42:17 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:42:18 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 10:42:18 | INFO | stdout | What's the relationship between object [229, 619] <region_fea> and object [354, 187, 899, 763] <region_fea>? ASSISTANT: **NETWORK ERROR DUE TO HIGH TRAFFIC. PLEASE REGENERATE OR REFRESH THIS PAGE.** (error_code: 1)</s>USER: What’s the relationship between object [229, 619] <region_fea>, object [354, 187, 899, 763] <region_fea> and object [region3]? ASSISTANT:
2024-02-02 10:43:26 | INFO | gradio_web_server | load_demo. ip: 127.0.0.1
2024-02-02 10:43:27 | INFO | gradio_web_server | Models: ['ferret-13b-v1.3']
2024-02-02 10:43:29 | INFO | stdout | Init Uploading Images.
2024-02-02 10:43:51 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 88
2024-02-02 10:43:51 | INFO | stdout | No location, copy original image in add_text
2024-02-02 10:43:51 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 10:43:51 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 10:43:51 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:43:51 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:43:52 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': "A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nWhat's the relationship between object [223, 602] <region_fea> and object [397, 215, 878, 718] <region_fea>, object [region3]? ASSISTANT:", 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['46c4c809a7f524e0d1c3eee44d673eee']"}
2024-02-02 10:43:52 | INFO | gradio_web_server | ==== add region_masks_in_prompts to request ====

2024-02-02 10:43:52 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 10:43:52 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 10:43:52 | INFO | stdout | What's the relationship between object [223, 602] <region_fea> and object [397, 215, 878, 718] <region_fea>, object [region3]? ASSISTANT:
2024-02-02 10:44:33 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-02-02 10:44:44 | INFO | gradio_web_server | args: Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:10000', concurrency_count=8, model_list_mode='reload', share=False, moderate=False, embed=False, add_region_feature=False)
2024-02-02 10:44:44 | INFO | gradio_web_server | Models: []
2024-02-02 10:44:44 | INFO | gradio_web_server | Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:10000', concurrency_count=8, model_list_mode='reload', share=False, moderate=False, embed=False, add_region_feature=False)
2024-02-02 10:44:44 | ERROR | stderr | /home/yochin/miniconda3/envs/ferret/lib/python3.10/site-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Textbox, please remove them: {'container': False}
2024-02-02 10:44:44 | ERROR | stderr |   warnings.warn(
2024-02-02 10:44:45 | ERROR | stderr | /home/yochin/miniconda3/envs/ferret/lib/python3.10/site-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Dropdown, please remove them: {'container': False}
2024-02-02 10:44:45 | ERROR | stderr |   warnings.warn(
2024-02-02 10:44:45 | INFO | stdout | Running on local URL:  http://0.0.0.0:7860
2024-02-02 10:44:45 | INFO | stdout | 
2024-02-02 10:44:45 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-02-02 10:46:07 | INFO | gradio_web_server | load_demo. ip: 127.0.0.1
2024-02-02 10:46:07 | INFO | gradio_web_server | Models: ['ferret-13b-v1.3']
2024-02-02 10:46:15 | INFO | stdout | Init Uploading Images.
2024-02-02 10:46:17 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 30
2024-02-02 10:46:17 | INFO | stdout | No location, copy original image in add_text
2024-02-02 10:46:17 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 10:46:17 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 10:46:17 | INFO | stdout | Input Image Size:(640, 480)
2024-02-02 10:46:17 | INFO | stdout | Input Image Size:(640, 480)
2024-02-02 10:46:18 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': 'A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nDescribe the image in details. ASSISTANT:', 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['b774a75b2fcfc3ce597f69f81d566394']"}
2024-02-02 10:46:18 | INFO | stdout | Input Image Size:(640, 480)
2024-02-02 10:46:18 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 10:46:18 | INFO | stdout | Describe the image in details. ASSISTANT:
2024-02-02 10:47:46 | INFO | gradio_web_server | The image depicts a cozy living room [12, 1, 982, 986] with various pieces [199, 89, 413, 722] of furniture [404, 577, 710, 881] and decor. The room [12, 1, 982, 986] features a comfortable couch [520, 417, 939, 764] located against the wall, accompanied by a chair [887, 462, 978, 622] [737, 398, 828, 465] on the right side. A coffee table is situated in the center of the space, and a rug [170, 757, 593, 988] [240, 790, 510, 981] lies beneath it.  On the walls, there are shelves [202, 91, 409, 721] filled with an array of books [211, 101, 397, 280], creating a warm and inviting atmosphere. A television [1, 394, 97, 723] is positioned on the left side of the room, providing entertainment options for the occupants. Additionally, there are a couple of vases [806, 380, 834, 423] placed on surfaces, adding to the room's decor, and a potted plant [765, 292, 865, 425] by the couch [565, 441, 869, 655] [520, 417, 939, 764], bringing a touch of nature indoors.
2024-02-02 10:47:46 | INFO | stdout | Input Image Size:(640, 480)
2024-02-02 10:49:37 | INFO | gradio_web_server | load_demo. ip: 127.0.0.1
2024-02-02 10:49:37 | INFO | gradio_web_server | Models: ['ferret-13b-v1.3']
2024-02-02 10:49:46 | INFO | stdout | Init Uploading Images.
2024-02-02 10:51:19 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 231
2024-02-02 10:51:19 | INFO | stdout | No location, copy original image in add_text
2024-02-02 10:51:20 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 10:51:20 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 10:51:20 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 10:51:20 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 10:51:20 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': 'A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nAfter explaining the overall photo from near to far, explaining the path to the area over the crosswalk, which is the current destination, with being aware of obstacles that exist on the path, and then summarize in three sentences. ASSISTANT:', 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['80a899e340fe51abc4e037a78066933e']"}
2024-02-02 10:51:20 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 10:51:20 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 10:51:20 | INFO | stdout | After explaining the overall photo from near to far, explaining the path to the area over the crosswalk, which is the current destination, with being aware of obstacles that exist on the path, and then summarize in three sentences. ASSISTANT:
2024-02-02 10:54:53 | INFO | gradio_web_server | load_demo. ip: 127.0.0.1
2024-02-02 10:54:53 | INFO | gradio_web_server | Models: ['ferret-13b-v1.3']
2024-02-02 10:54:57 | INFO | stdout | Init Uploading Images.
2024-02-02 10:55:01 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 206
2024-02-02 10:55:01 | INFO | stdout | No location, copy original image in add_text
2024-02-02 10:55:02 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 10:55:02 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 10:55:02 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 10:55:02 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 10:55:02 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': 'A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nAfter explaining the overall photo from near to far, explaining the path to the current destination across the crosswalk, paying attention to obstacles along the path, and then summarize in three sentences. ASSISTANT:', 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['80a899e340fe51abc4e037a78066933e']"}
2024-02-02 10:55:02 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 10:55:02 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 10:55:02 | INFO | stdout | After explaining the overall photo from near to far, explaining the path to the current destination across the crosswalk, paying attention to obstacles along the path, and then summarize in three sentences. ASSISTANT:
2024-02-02 10:55:23 | INFO | gradio_web_server | A city street scene with a crosswalk [226, 501, 654, 705] and traffic lights [100, 336, 150, 528].
2024-02-02 10:55:23 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 10:57:02 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 167
2024-02-02 10:57:03 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 10:57:03 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 10:57:03 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 10:57:03 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 10:57:03 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': 'A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nAfter explaining the overall photo from near to far, explaining the path to the current destination across the crosswalk, paying attention to obstacles along the path, and then summarize in three sentences. ASSISTANT: A city street scene with a crosswalk [226, 501, 654, 705] and traffic lights [100, 336, 150, 528].</s>USER: After explaining the overall photo from near to far, explaining the path to the current destination across the crosswalk, paying attention to obstacles along the path. ASSISTANT:', 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['80a899e340fe51abc4e037a78066933e']"}
2024-02-02 10:57:03 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 10:57:03 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 10:57:03 | INFO | stdout | After explaining the overall photo from near to far, explaining the path to the current destination across the crosswalk, paying attention to obstacles along the path, and then summarize in three sentences. ASSISTANT: A city street scene with a crosswalk [226, 501, 654, 705] and traffic lights [100, 336, 150, 528].</s>USER: After explaining the overall photo from near to far, explaining the path to the current destination across the crosswalk, paying attention to obstacles along the path. ASSISTANT:
2024-02-02 10:57:18 | INFO | gradio_web_server | A city street scene with a crosswalk [226, 501, 654, 705] and traffic lights [100, 336, 150, 528].
2024-02-02 10:57:18 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 11:03:12 | INFO | stdout | Init Uploading Images.
2024-02-02 11:03:15 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 102
2024-02-02 11:03:16 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 11:03:16 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 11:03:16 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 11:03:16 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 11:03:16 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': 'A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nAfter explaining the overall photo from near to far, explaining the path to the current destination across the crosswalk, paying attention to obstacles along the path, and then summarize in three sentences. ASSISTANT: A city street scene with a crosswalk [226, 501, 654, 705] and traffic lights [100, 336, 150, 528].</s>USER: After explaining the overall photo from near to far, explaining the path to the current destination across the crosswalk, paying attention to obstacles along the path. ASSISTANT: A city street scene with a crosswalk [226, 501, 654, 705] and traffic lights [100, 336, 150, 528].</s>USER: What are the things I should be cautious about when I visit here? Tell me the coordinates in response. ASSISTANT:', 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['80a899e340fe51abc4e037a78066933e']"}
2024-02-02 11:03:16 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 11:03:16 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 11:03:16 | INFO | stdout | After explaining the overall photo from near to far, explaining the path to the current destination across the crosswalk, paying attention to obstacles along the path, and then summarize in three sentences. ASSISTANT: A city street scene with a crosswalk [226, 501, 654, 705] and traffic lights [100, 336, 150, 528].</s>USER: After explaining the overall photo from near to far, explaining the path to the current destination across the crosswalk, paying attention to obstacles along the path. ASSISTANT: A city street scene with a crosswalk [226, 501, 654, 705] and traffic lights [100, 336, 150, 528].</s>USER: What are the things I should be cautious about when I visit here? Tell me the coordinates in response. ASSISTANT:
2024-02-02 11:03:40 | INFO | gradio_web_server | When visiting this street, be cautious of traffic signals [100, 336, 150, 528], and pedestrians crossing the street [226, 501, 654, 705].
2024-02-02 11:03:40 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 11:04:02 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 111
2024-02-02 11:04:03 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 11:04:03 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 11:04:03 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 11:04:03 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 11:04:03 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': 'A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nAfter explaining the overall photo from near to far, explaining the path to the current destination across the crosswalk, paying attention to obstacles along the path, and then summarize in three sentences. ASSISTANT: A city street scene with a crosswalk [226, 501, 654, 705] and traffic lights [100, 336, 150, 528].</s>USER: After explaining the overall photo from near to far, explaining the path to the current destination across the crosswalk, paying attention to obstacles along the path. ASSISTANT: A city street scene with a crosswalk [226, 501, 654, 705] and traffic lights [100, 336, 150, 528].</s>USER: What are the things I should be cautious about when I visit here? Tell me the coordinates in response. ASSISTANT: When visiting this street, be cautious of traffic signals [100, 336, 150, 528], and pedestrians crossing the street [226, 501, 654, 705].</s>USER: Explain the path to the current destination across the crosswalk, paying attention to obstacles along the path. ASSISTANT:', 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['80a899e340fe51abc4e037a78066933e']"}
2024-02-02 11:04:03 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 11:04:03 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 11:04:03 | INFO | stdout | After explaining the overall photo from near to far, explaining the path to the current destination across the crosswalk, paying attention to obstacles along the path, and then summarize in three sentences. ASSISTANT: A city street scene with a crosswalk [226, 501, 654, 705] and traffic lights [100, 336, 150, 528].</s>USER: After explaining the overall photo from near to far, explaining the path to the current destination across the crosswalk, paying attention to obstacles along the path. ASSISTANT: A city street scene with a crosswalk [226, 501, 654, 705] and traffic lights [100, 336, 150, 528].</s>USER: What are the things I should be cautious about when I visit here? Tell me the coordinates in response. ASSISTANT: When visiting this street, be cautious of traffic signals [100, 336, 150, 528], and pedestrians crossing the street [226, 501, 654, 705].</s>USER: Explain the path to the current destination across the crosswalk, paying attention to obstacles along the path. ASSISTANT:
2024-02-02 11:04:24 | INFO | gradio_web_server | To reach the destination across the crosswalk, one should be aware of the traffic lights [100, 336, 150, 528], the crosswalk [226, 501, 654, 705], and any pedestrians that may be crossing the street.
2024-02-02 11:04:24 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 11:04:38 | INFO | gradio_web_server | load_demo. ip: 127.0.0.1
2024-02-02 11:04:38 | INFO | gradio_web_server | Models: ['ferret-13b-v1.3']
2024-02-02 11:04:58 | INFO | stdout | Init Uploading Images.
2024-02-02 11:05:21 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 113
2024-02-02 11:05:21 | INFO | stdout | No location, copy original image in add_text
2024-02-02 11:05:21 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 11:05:21 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 11:05:21 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 11:05:21 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 11:05:22 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': 'A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nExplain the overall photo from near to far, explaining the path to the current destination across the crosswalk. ASSISTANT:', 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['80a899e340fe51abc4e037a78066933e']"}
2024-02-02 11:05:22 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 11:05:22 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 11:05:22 | INFO | stdout | Explain the overall photo from near to far, explaining the path to the current destination across the crosswalk. ASSISTANT:
2024-02-02 11:06:21 | INFO | gradio_web_server | The image depicts a city street [8, 405, 952, 987] with a crosswalk [225, 507, 611, 694] in the middle of it. The crosswalk [225, 507, 611, 694] leads to a destination on the other side of the street. To navigate across the street safely, one would follow the crosswalk's markings and wait for the traffic light [128, 341, 162, 383], which is currently red. The traffic light is positioned on the left side of the crosswalk. There are also blue and yellow poles [688, 514, 786, 995] near the crosswalk, which serve as guides for pedestrians [304, 487, 332, 529] and help them stay on the correct path.
2024-02-02 11:06:21 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 11:06:31 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 29
2024-02-02 11:06:32 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 11:06:32 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 11:06:32 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 11:06:32 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 11:06:32 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': "A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nExplain the overall photo from near to far, explaining the path to the current destination across the crosswalk. ASSISTANT: The image depicts a city street [8, 405, 952, 987] with a crosswalk [225, 507, 611, 694] in the middle of it. The crosswalk [225, 507, 611, 694] leads to a destination on the other side of the street. To navigate across the street safely, one would follow the crosswalk's markings and wait for the traffic light [128, 341, 162, 383], which is currently red. The traffic light is positioned on the left side of the crosswalk. There are also blue and yellow poles [688, 514, 786, 995] near the crosswalk, which serve as guides for pedestrians [304, 487, 332, 529] and help them stay on the correct path.</s>USER: Summarize in three sentences. ASSISTANT:", 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['80a899e340fe51abc4e037a78066933e']"}
2024-02-02 11:06:32 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 11:06:32 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 11:06:32 | INFO | stdout | Explain the overall photo from near to far, explaining the path to the current destination across the crosswalk. ASSISTANT: The image depicts a city street [8, 405, 952, 987] with a crosswalk [225, 507, 611, 694] in the middle of it. The crosswalk [225, 507, 611, 694] leads to a destination on the other side of the street. To navigate across the street safely, one would follow the crosswalk's markings and wait for the traffic light [128, 341, 162, 383], which is currently red. The traffic light is positioned on the left side of the crosswalk. There are also blue and yellow poles [688, 514, 786, 995] near the crosswalk, which serve as guides for pedestrians [304, 487, 332, 529] and help them stay on the correct path.</s>USER: Summarize in three sentences. ASSISTANT:
2024-02-02 11:06:38 | INFO | gradio_web_server | In a nutshell, a red traffic light at the crosswalk.
2024-02-02 11:06:38 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 11:07:53 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 40
2024-02-02 11:07:53 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 11:07:53 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 11:07:53 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 11:07:53 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 11:07:54 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': "A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nExplain the overall photo from near to far, explaining the path to the current destination across the crosswalk. ASSISTANT: The image depicts a city street [8, 405, 952, 987] with a crosswalk [225, 507, 611, 694] in the middle of it. The crosswalk [225, 507, 611, 694] leads to a destination on the other side of the street. To navigate across the street safely, one would follow the crosswalk's markings and wait for the traffic light [128, 341, 162, 383], which is currently red. The traffic light is positioned on the left side of the crosswalk. There are also blue and yellow poles [688, 514, 786, 995] near the crosswalk, which serve as guides for pedestrians [304, 487, 332, 529] and help them stay on the correct path.</s>USER: Summarize in three sentences. ASSISTANT: In a nutshell, a red traffic light at the crosswalk.</s>USER: Summarize the path described in 3 lines. ASSISTANT:", 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['80a899e340fe51abc4e037a78066933e']"}
2024-02-02 11:07:54 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 11:07:54 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 11:07:54 | INFO | stdout | Explain the overall photo from near to far, explaining the path to the current destination across the crosswalk. ASSISTANT: The image depicts a city street [8, 405, 952, 987] with a crosswalk [225, 507, 611, 694] in the middle of it. The crosswalk [225, 507, 611, 694] leads to a destination on the other side of the street. To navigate across the street safely, one would follow the crosswalk's markings and wait for the traffic light [128, 341, 162, 383], which is currently red. The traffic light is positioned on the left side of the crosswalk. There are also blue and yellow poles [688, 514, 786, 995] near the crosswalk, which serve as guides for pedestrians [304, 487, 332, 529] and help them stay on the correct path.</s>USER: Summarize in three sentences. ASSISTANT: In a nutshell, a red traffic light at the crosswalk.</s>USER: Summarize the path described in 3 lines. ASSISTANT:
2024-02-02 11:08:00 | INFO | gradio_web_server | In a nutshell, the crosswalk is marked with blue and yellow stripes.
2024-02-02 11:08:00 | INFO | stdout | Input Image Size:(914, 800)
2024-02-02 11:21:43 | INFO | gradio_web_server | load_demo. ip: 127.0.0.1
2024-02-02 11:21:43 | INFO | gradio_web_server | Models: []
2024-02-02 11:21:57 | INFO | gradio_web_server | load_demo. ip: 127.0.0.1
2024-02-02 11:21:57 | INFO | gradio_web_server | Models: []
2024-02-02 11:21:58 | INFO | gradio_web_server | load_demo. ip: 127.0.0.1
2024-02-02 11:21:58 | INFO | gradio_web_server | Models: ['ferret-13b-v1.3']
2024-02-02 11:22:00 | INFO | gradio_web_server | load_demo. ip: 127.0.0.1
2024-02-02 11:22:00 | INFO | gradio_web_server | Models: ['ferret-13b-v1.3']
2024-02-02 11:22:07 | INFO | stdout | Init Uploading Images.
2024-02-02 11:22:34 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 29
2024-02-02 11:22:34 | INFO | stdout | No location, copy original image in add_text
2024-02-02 11:22:34 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 11:22:34 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 11:22:34 | INFO | stdout | Input Image Size:(615, 446)
2024-02-02 11:22:34 | INFO | stdout | Input Image Size:(615, 446)
2024-02-02 11:22:34 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': 'A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nWhat is the object [region0]? ASSISTANT:', 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['2e388e61e41d26b104b50b7e3741a028']"}
2024-02-02 11:22:34 | INFO | stdout | Input Image Size:(615, 446)
2024-02-02 11:22:34 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 11:22:34 | INFO | stdout | What is the object [region0]? ASSISTANT:
2024-02-02 11:22:48 | INFO | gradio_web_server | The object [1, 0, 267, 718] is a wall. It appears to be part of the interior of a bathroom or a tiled room.
2024-02-02 11:22:48 | INFO | stdout | Input Image Size:(615, 446)
2024-02-02 11:22:57 | INFO | gradio_web_server | clear_history. ip: 127.0.0.1
2024-02-02 11:23:01 | INFO | stdout | Init Uploading Images.
2024-02-02 11:23:19 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 28
2024-02-02 11:23:19 | INFO | stdout | No location, copy original image in add_text
2024-02-02 11:23:19 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 11:23:19 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 11:23:19 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 11:23:19 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 11:23:20 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': "A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nWhat's the object [region0]? ASSISTANT:", 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['46c4c809a7f524e0d1c3eee44d673eee']"}
2024-02-02 11:23:20 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 11:23:20 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 11:23:20 | INFO | stdout | What's the object [region0]? ASSISTANT:
2024-02-02 11:23:25 | INFO | gradio_web_server | The object [4, 325, 995, 995] is snow, which serves as the setting for the scene.
2024-02-02 11:23:25 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 11:24:43 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 39
2024-02-02 11:24:43 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 11:24:43 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 11:24:43 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 11:24:43 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 11:24:43 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': "A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nWhat's the object [region0]? ASSISTANT: The object [4, 325, 995, 995] is snow, which serves as the setting for the scene.</s>USER: What’s the object [400, 200, 900, 800]? ASSISTANT:", 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['46c4c809a7f524e0d1c3eee44d673eee']"}
2024-02-02 11:24:43 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 11:24:43 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 11:24:43 | INFO | stdout | What's the object [region0]? ASSISTANT: The object [4, 325, 995, 995] is snow, which serves as the setting for the scene.</s>USER: What’s the object [400, 200, 900, 800]? ASSISTANT:
2024-02-02 11:24:49 | INFO | gradio_web_server | The object [400, 200, 900, 800] is a white dog lying in the snow.
2024-02-02 11:24:49 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 15:37:17 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-02-02 15:37:59 | INFO | gradio_web_server | args: Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:10000', concurrency_count=8, model_list_mode='reload', share=False, moderate=False, embed=False, add_region_feature=False)
2024-02-02 15:37:59 | INFO | gradio_web_server | Models: []
2024-02-02 15:37:59 | INFO | gradio_web_server | Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:10000', concurrency_count=8, model_list_mode='reload', share=False, moderate=False, embed=False, add_region_feature=False)
2024-02-02 15:37:59 | ERROR | stderr | /home/yochin/miniconda3/envs/ferret/lib/python3.10/site-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Textbox, please remove them: {'container': False}
2024-02-02 15:37:59 | ERROR | stderr |   warnings.warn(
2024-02-02 15:38:00 | ERROR | stderr | /home/yochin/miniconda3/envs/ferret/lib/python3.10/site-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Dropdown, please remove them: {'container': False}
2024-02-02 15:38:00 | ERROR | stderr |   warnings.warn(
2024-02-02 15:38:00 | INFO | stdout | Running on local URL:  http://0.0.0.0:7860
2024-02-02 15:38:00 | INFO | stdout | 
2024-02-02 15:38:00 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-02-02 15:38:58 | ERROR | stderr | [33mWARNING[0m:  Invalid HTTP request received.
2024-02-02 15:38:58 | ERROR | stderr | [33mWARNING[0m:  Invalid HTTP request received.
2024-02-02 15:38:58 | ERROR | stderr | [33mWARNING[0m:  Invalid HTTP request received.
2024-02-02 15:39:01 | INFO | gradio_web_server | load_demo. ip: 127.0.0.1
2024-02-02 15:39:01 | INFO | gradio_web_server | Models: ['ferret-13b-v1.3']
2024-02-02 15:39:15 | INFO | stdout | Init Uploading Images.
2024-02-02 15:39:24 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 70
2024-02-02 15:39:24 | INFO | stdout | No location, copy original image in add_text
2024-02-02 15:39:24 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 15:39:24 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 15:39:24 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 15:39:24 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 15:39:24 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': "A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nWhat's the relationship between object [region0] and object [region1]? ASSISTANT:", 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['46c4c809a7f524e0d1c3eee44d673eee']"}
2024-02-02 15:39:24 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 15:39:24 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 15:39:24 | INFO | stdout | What's the relationship between object [region0] and object [region1]? ASSISTANT:
2024-02-02 15:39:47 | INFO | gradio_web_server | Region [4, 364, 996, 993] showing snowy ground. Region [1, 355, 426, 561] showing white snow. The snow in the first region appears to be covering the ground, suggesting it's a snowy landscape. The snow in the second region is lighter, possibly signifying a change in the amount of snowfall or a shift in the weather.
2024-02-02 15:39:47 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 15:40:02 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-02-02 15:40:19 | INFO | gradio_web_server | args: Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:10000', concurrency_count=8, model_list_mode='reload', share=False, moderate=False, embed=False, add_region_feature=True)
2024-02-02 15:40:19 | INFO | gradio_web_server | Models: []
2024-02-02 15:40:19 | INFO | gradio_web_server | Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:10000', concurrency_count=8, model_list_mode='reload', share=False, moderate=False, embed=False, add_region_feature=True)
2024-02-02 15:40:19 | ERROR | stderr | /home/yochin/miniconda3/envs/ferret/lib/python3.10/site-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Textbox, please remove them: {'container': False}
2024-02-02 15:40:19 | ERROR | stderr |   warnings.warn(
2024-02-02 15:40:20 | ERROR | stderr | /home/yochin/miniconda3/envs/ferret/lib/python3.10/site-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Dropdown, please remove them: {'container': False}
2024-02-02 15:40:20 | ERROR | stderr |   warnings.warn(
2024-02-02 15:40:20 | INFO | stdout | Running on local URL:  http://0.0.0.0:7860
2024-02-02 15:40:20 | INFO | stdout | 
2024-02-02 15:40:20 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-02-02 15:40:42 | INFO | gradio_web_server | load_demo. ip: 127.0.0.1
2024-02-02 15:40:42 | INFO | gradio_web_server | Models: []
2024-02-02 15:41:28 | INFO | gradio_web_server | load_demo. ip: 127.0.0.1
2024-02-02 15:41:28 | INFO | gradio_web_server | Models: ['ferret-13b-v1.3']
2024-02-02 15:41:31 | INFO | stdout | Init Uploading Images.
2024-02-02 15:41:39 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 70
2024-02-02 15:41:39 | INFO | stdout | No location, copy original image in add_text
2024-02-02 15:41:40 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 15:41:40 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 15:41:40 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 15:41:40 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 15:41:40 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': "A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nWhat's the relationship between object [667, 464] <region_fea> and object [107, 460, 397, 787] <region_fea>? ASSISTANT:", 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['46c4c809a7f524e0d1c3eee44d673eee']"}
2024-02-02 15:41:40 | INFO | gradio_web_server | ==== add region_masks_in_prompts to request ====

2024-02-02 15:41:40 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 15:41:40 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 15:41:40 | INFO | stdout | What's the relationship between object [667, 464] <region_fea> and object [107, 460, 397, 787] <region_fea>? ASSISTANT:
2024-02-02 15:43:36 | INFO | gradio_web_server | load_demo. ip: 127.0.0.1
2024-02-02 15:43:36 | INFO | gradio_web_server | Models: ['ferret-13b-v1.3']
2024-02-02 15:43:40 | INFO | stdout | Init Uploading Images.
2024-02-02 15:43:47 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 70
2024-02-02 15:43:47 | INFO | stdout | No location, copy original image in add_text
2024-02-02 15:43:47 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 15:43:47 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 15:43:47 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 15:43:47 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 15:43:47 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': "A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nWhat's the relationship between object [687, 498] <region_fea> and object [11, 458, 394, 718] <region_fea>? ASSISTANT:", 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['46c4c809a7f524e0d1c3eee44d673eee']"}
2024-02-02 15:43:47 | INFO | gradio_web_server | ==== add region_masks_in_prompts to request ====

2024-02-02 15:43:47 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 15:43:48 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 15:43:48 | INFO | stdout | What's the relationship between object [687, 498] <region_fea> and object [11, 458, 394, 718] <region_fea>? ASSISTANT:
2024-02-02 15:46:00 | INFO | gradio_web_server | load_demo. ip: 127.0.0.1
2024-02-02 15:46:00 | INFO | gradio_web_server | Models: ['ferret-13b-v1.3']
2024-02-02 15:46:03 | INFO | stdout | Init Uploading Images.
2024-02-02 15:46:09 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 70
2024-02-02 15:46:09 | INFO | stdout | No location, copy original image in add_text
2024-02-02 15:46:10 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 15:46:10 | INFO | gradio_web_server | model_name: ferret-13b-v1.3, worker_addr: http://localhost:40000
2024-02-02 15:46:10 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 15:46:10 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 15:46:10 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-13b-v1.3', 'prompt': "A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nWhat's the relationship between object [223, 630] <region_fea> and object [360, 212, 827, 797] <region_fea>? ASSISTANT:", 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['46c4c809a7f524e0d1c3eee44d673eee']"}
2024-02-02 15:46:10 | INFO | gradio_web_server | ==== add region_masks_in_prompts to request ====

2024-02-02 15:46:10 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 15:46:10 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 15:46:10 | INFO | stdout | What's the relationship between object [223, 630] <region_fea> and object [360, 212, 827, 797] <region_fea>? ASSISTANT:
2024-02-02 15:48:05 | INFO | gradio_web_server | load_demo. ip: 127.0.0.1
2024-02-02 15:48:05 | INFO | gradio_web_server | Models: ['ferret-7b-v1.3']
2024-02-02 15:48:07 | INFO | stdout | Init Uploading Images.
2024-02-02 15:48:14 | INFO | gradio_web_server | add_text. ip: 127.0.0.1. len: 70
2024-02-02 15:48:14 | INFO | stdout | No location, copy original image in add_text
2024-02-02 15:48:14 | INFO | gradio_web_server | http_bot. ip: 127.0.0.1
2024-02-02 15:48:14 | INFO | gradio_web_server | model_name: ferret-7b-v1.3, worker_addr: http://localhost:40000
2024-02-02 15:48:14 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 15:48:14 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 15:48:14 | INFO | gradio_web_server | ==== request ====
{'model': 'ferret-7b-v1.3', 'prompt': "A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>\nWhat's the relationship between object [215, 651] <region_fea> and object [345, 200, 886, 901] <region_fea>? ASSISTANT:", 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': '</s>', 'images': "List of 1 images: ['46c4c809a7f524e0d1c3eee44d673eee']"}
2024-02-02 15:48:14 | INFO | gradio_web_server | ==== add region_masks_in_prompts to request ====

2024-02-02 15:48:14 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 15:48:14 | INFO | stdout | Input Prompt: A chat between a human and an AI that understands visuals. In images, [x, y] denotes points: top-left [0, 0], bottom-right [width-1, height-1]. Increasing x moves right; y moves down. Bounding box: [x1, y1, x2, y2]. Image size: 1000x1000. Follow instructions.  USER: <image>
2024-02-02 15:48:14 | INFO | stdout | What's the relationship between object [215, 651] <region_fea> and object [345, 200, 886, 901] <region_fea>? ASSISTANT:
2024-02-02 15:48:29 | INFO | gradio_web_server | The objects [54, 472, 512, 743] and [345, 200, 886, 901] are a snake and a dog, respectively. From their proximity and the way they're positioned, it's clear that the snake and the dog are in a friendly manner, with the snake coiling around the dog's neck. The dog is lying down in the snow, and the snake is resting on the dog's body, suggesting a trusting and friendly relationship between them.
2024-02-02 15:48:29 | INFO | stdout | Input Image Size:(697, 465)
2024-02-02 16:32:51 | INFO | stdout | Keyboard interruption in main thread... closing server.
